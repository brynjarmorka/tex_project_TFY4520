\chapter{Discussion}
\label{chap:discussion}


% % Ga Ka where Ka2 is not visible
% % point of the paragraph: empirical view is good enough
% In \cref{fig:theory:GaAs30keV-K-lines} the calibrated peak of Ga K$\alpha$ is directly on K$\alpha_1$ and the K$\alpha_\textnormal{HyperSpy}$, the emission from K$\alpha_2$ is missing.
% The energy difference is too small to differentiate the two peaks in EDS, but the peak has no left-shift, implying that the peak is not a mixture of K$\alpha_1$ and K$\alpha_2$.
% The peak shape is \brynjar{calculate the shape}, which is close to a perfect Gaussian.
% There are possible theoretical explainations for the lacking emission from K$\alpha_2$.
% One explaination is the quantum mechanical effect called \dots, where two close lines appear as one stronger line.
% This effect is not only present in EDS, but also in \dots.
% Another explaination is that Ga K$\alpha_2$ could also be weaker than K$\alpha_1$, but there is no reason for this to be the case.
% The take away from this is that the empirical view tends to be good enough for EDS analysis.


The discussion is presented in this chapter.
Producing code from scratch is both a time-consuming process and a learning process.
While developing the code, the author learned a lot about EDS analysis and  ideas emerged for how EDS analysis could be improved.
This chapter begins with an initial discussion of the qualitative results, and then it connects the sub-problems to the results and work done in the project.
The order of the sub-problems is the same as in \cref{chap:introduction}, which is based on the work process.
% The chapter ends with a discussion of the \hyperref[mainproblem]{Main problem}.



\section{General results from the spectra}
\label{sec:discussion:general}

This section starts with peak intensities, then the background, and finally some strays observed.


\subsection{Peak intensities}
\label{sec:discussion:general:intensities}

% signal-to-noise ratio
All the spectra have peaks with high peak-to-background ratio, at least for the main peaks. %discuss: sampling good enough? I do not know if i miss some peaks, but the ones i have are nice for qualitative analysis at least.
Good sampling settings give a high signal-to-noise ratio, which is important for analysis.
The high peaks in the spectrum are well-defined and fit the Gaussian curves well.
These peaks are good enough for qualitative analysis, but there are some smaller signals which have been harder to interpret.
A small signal can in some cases be interpreted in a qualitative analysis but is hard to use properly in a quantitative analysis.
Interpreting every small signal as radiation from a specific element is not always correct.
The small signal of Fe K$\alpha$ at 6.4 keV in the FIB stub spectrum is an example of this, where there is a 20\% increase of counts compared to the background.
It might be that this signal is from Fe, but it might also just be noise or an artifact.
\cref{tab:theory:Ga-lines} list the Ga-lines and their weights, and it is clear that some lines have very low weights.
In this project it was decided not to use a hard threshold for the signal-to-noise ratio, which can be helpful in some cases.
Setting a hard threshold should be based on both literature and empirical data for the specific detector setup.
An issue with setting a hard threshold is that it can be too strict, which can lead to missing peaks of elements which are low in concentration.
If the sampling settings were not good enough, some peaks can be missing in the spectra.
One example of this is in the NW spectrum: the low As K$\beta$ peak in the 15 kV spectrum has an overvoltage of ~3 keV and is visible, but the Cu K$\alpha$ peak in the 10 kV spectrum with overvoltage of ~2 keV is not visible.
Multiple data sets on the same area can be used to verify the sampling settings, since missing peaks in one data set can be visible in another data set.
In general, the signals in the spectra are best in the 30 kV spectra.
In conclusion, it is assumed that the sampling settings were good, at lest when it is considered that there are multiple spectra from the same area.


% Peak intensities in relation to the element
Different elements do give different peak intensities, as expected.
The intensity is dependent on the atomic number, which affects both the fluorescent yield and ionization cross section.
In the GaAs spectrum, with Ga ($Z=31$) and As ($Z=33$), the Ga peaks have both higher max counts and higher sum counts, given in \cref{tab:results:detector:settings} and \cref{tab:results:ratios}.
From the theory of fluorescent yield and \cref{eq:empirical:fluorescentyieldapprox}, one would expect the As peaks to be more intense than the Ga peaks, but this is not the case.
For the K-peaks this could be an effect of the overvoltage, but that would not explain the difference in the L-peaks.
Another factor affected by the atomic number is the absorption, which is higher for heavier elements.
In the k-factor approach with TEM thin samples the absorption is assumed to be negligible, which is not the case for bulk samples.
Thus, some correction for the absorption should be done for bulk samples, which would be Z dependent.
In addition, X-rays with lower energies are more absorbed than X-rays with higher energies.
The ZAF matrix correction for SEM EDS data would correct for the absorption, but that have not been done in this project.
Looking into the ZAF matrix correction would be a good next step for this project.
In general, the generation of characteristic X-rays is a complex process, which is why much of the work done in EDS analysis is empirical.


% height of the peaks in relation to the settings
The heights, or intensities, of the peaks are varying a lot.
The plots of the spectra in \cref{fig:results:Spectra_Al} to \cref{fig:results:Spectra_NW} are normalized, and the total counts and maximum counts are included in \cref{tab:results:detector:settings}.
No direct pattern between the amount of counts and the settings are apparent.
Trends observed are that higher counts are obtained by increasing the current or the acceleration voltage, but this also increases the dead time.
To figure out a pattern, fewer variables should be changed at the same time.
This was done for the nanowire sample, where the $I_\textnormal{beam}$ and live time was kept constant.
Still, a direct pattern is not apparent.
As stated in Goldstein, "high counts and stable peak structures are critical for successful peak intensity measurements", especially to identify minor and trace constituents \cite[page 318]{goldstein_scanning_2018}.
The relation between the counts and settings could be further investigated to figure out which settings yield the best spectra in terms of good count statistics.

% the highest peaks, 
The main peaks have good count statistics, and the peak with the highest count is below 5 keV in all the spectra.
For the spectra with strong K and L peaks from the same element, i.e. the lines of Ga, As, and Mo, the L-peaks are more intense than the K-peaks.
In the Mo 30 kV spectrum, the K$\alpha$ peak is only 2\% the height of the L$\alpha$ peak.
This low intensity of the K$\alpha$ peak is partially due to lower overvoltage, since the peak is above U/2.
For the Ga and As the relative intensity of the 30 kV spectra in the bulk and nanowire is not similar.
The K-lines in the bulk sample is around 2 times as intense as the K-lines in the nanowire sample.
Both spectra are normalized to the L-line of Ga.
It was expected that the nanowire would give lower relative intensity for K-lines, because it is a thin sample where less of the lower level X-rays are absorbed, and thus getting lower relative intensity of higher energy peaks.
Using \cref{tab:results:ratios} with the ratios of the K-lines to the L-lines, it is clear that even the ratios of Ga and As lines change in the spectra with different $V_\textnormal{acc}$.
When applying the theoretically estimated k-factor for the respective spectrum, the ratios get closer to 1, but there is still a spread.
This implies that the settings for acquiring spectra is important for the intensity of the peaks, which again is important for the quantitative analysis.
Investigation of which settings yield better spectra should improve the accuracy of the quantitative analysis, and can be done in future projects.


% Missing Cu La peak
Even though most of the spectra appear to have good intensities and good signal-to-noise ratio, there are some strange results.
From the results it is clear that the Cu-tape is giving a bad Cu signal and should not be used as a Cu reference.
The strongest signal from the Cu-tape is from C, which is probably from the sticky tape material.
Regardless, the strangest Cu-tape result is the completely missing signal from Cu L$\alpha$ in the Cu-tape 30 kV spectrum.
This spectrum has a clear signal from Cu K$\alpha$ and Cu K$\beta$, but no signal from Cu L$\alpha$ at all.
In general the L-peaks are stronger than the K-peaks.
In the 30 kV NW spectrum, Mo is giving a low but clear signal at the L$\alpha$ line, and even a small signal at the L$\beta$ and Ll lines, but no signal from the Mo K$\alpha$ line.
This is not strange as even the K-line signal from pure Mo is quite low, which is probably due to low overvoltage of the high K-peak.
The missing Cu L$\alpha$ signal is even stranger when comparing it to the NW spectra, because the Cu signal in the NW spectra all have a clear signal from Cu L$\alpha$ which is around 30\% stronger than the Cu K$\alpha$ signal.
When the spectra on the Cu-tape sample area was taken, beam made visible damages on the surface, which can be part of the explanation of the missing signal.
In the end, the spectra from the Cu-tape are regarded as unreliable.
Finding both K-lines and L-lines is an important aspect of qualitative EDS analysis, because a present K-line without an L-line indicate that the identified element is not the correct one.
The result with the missing L-line show that, unfortunately, it is possible to acquire spectra where a K-line is present, but the L-line is missing.
Further, investigating this could reveal if this is an issue with the Cu-tape, the detector, the settings, or an artifact that can appear in other spectra.


% width of the peaks
From the spectra shown and \cref{tab:results:ratios} including the FWHM, it is clear that the peaks broaden with higher energy.
Increase of the FWHM with energy is expected, as explained in subsection 16.1.1 in Goldstein \cite{goldstein_scanning_2018}.
From the FWHM the resolution of the detector can be calculated with a conversion factor, since the resolution of EDS is defined as the FWHM of Mn K$\alpha$.
This was done by Skomedal, and was considered to be a part of this project too.
However, other parts of the project was prioritized.


One of the prioritized parts was to do calibrations, and it was quantified that the AZtec calibration was off, which might be connected to the center of the zero peak.
With the most accurate calibration, the zero peak did not have its center at 0 keV.
In the spectra the zero peak start before 0 keV and has its maximum at 0.008 keV.
Since AZtec is a black box, it is not known how the calibration is done.
If AZtec is using the zero peak to calibrate, this could be the reason for less accurate calibration.
Another possibility is that the calibration was done on installation, and that the detector has not been calibrated since then.


%  overlapping peaks
A challenge which is unaffected by poor calibration is overlapping peaks.
Section 20.3 in Goldstein explains how to deal with overlapping peaks \cite{goldstein_scanning_2018}.
Dealing with overlapping peaks in model fitting is just modelling two Gaussian curves on top of each other.
In the self produced fitting, the Gaussians have three parameters: center, standard deviation and height.
Model fitting in HyperSpy is done with fixed centers, which means that the peak centers cannot change.
Calibration can affect the result if fitting is done with a model where the peak centers cannot change.
If the center of the smaller peak is off, larger peak will dominate the fitting and the smaller peak will get a lower intensity than it should.
This problem is not present in the self produced fitting, since the peak centers are free parameters.
An example of slightly overlapping peaks is the As K$\alpha$ and Ga K$\beta$ peaks in the GaAs bulk and NW spectra.
An example of severely overlapping peaks is the Mo L$\alpha$ and Mo L$\beta_1$ peaks in the Mo spectra.
The Mo L$\alpha$ peak has one of the highest error in the peak accuracy in \cref{tab:results:calibration-peak-accuracy}, where the calibrations are compared.
The reason for this is that the overlapping Mo L-peaks are identified as just one peak by the automatic peak finder.
Thus, the severely overlapping peak is modelled as one single peak which has its center shifted towards the middle of the two peaks.
That is why all the calibrations miss the Mo L$\alpha$ peak with 20 eV.
This issue was fixed manually when making the Mo L$\alpha$ and Mo K$\alpha$ calibration, and can with more time be fixed in the automatic peak finder.
% \brynjar{Figure of Mo overlapping peaks?}




























\subsection{The background}
\label{sec:discussion:general:background}
% the background with shape and intensity
Another problem in the self produced code that can improve with more time is fitting the background.
An idea that emerged towards the end of the project was to model the background as a spline.
A spline is a piece wise polynomial function connected in knots.
The fit of the background was observed to be bad at lower energies, where the background fit is more crucial for finding the right intensity of a peak.
It is more crucial, because the background change more with energy at lower energies.
The first iteration of the spline background would be to have the knot at the highest peak, because of the observation that the background decrease to around 50-10\% after the highest peak.


% highest peak effect on the background
All the spectra show the same behavior that the background is higher before the highest peak than after it.
In the 30 kV GaAs spectrum the background is at 2200 counts before the overlapping L-line peaks, and falls to 500 counts after the peaks.
In the 30 kV Si spectrum the background falls from 2000 to 200 counts after the main peak.
The background shape in Si 30 kV is almost linear from 0.6 to 1.6 keV ending at 2000 counts, then it drops to 200 after the peak at 1.6-1.9 keV.
After the drop the peak follow the expected shape, illustrated in \cref{fig:theory:expected_spectrum_Skomedal} and \cref{fig:theory:expected_background}.
In the 5 and 10 kV Si spectra the background falls from 2500 to 1000 counts after the main peak.
The Mo 10 kV spectrum, which is the spectrum with overall most background counts, has a background signal which falls from 5400 to 2900 counts after the main peak.
In the nanowire spectra, which in general have the lower background counts, the background falls around 50\% after the high L-peaks.
The reason for the higher background to the left of the highest peak is that the X-rays formed with energy above the highest peak can be absorbed and re-emitted with the energy of the line in the highest peak.
When the code for the background was written, the effect of the highest peak was not considered, which resulted in visible bad background fits at the lower energies.
This is shown in \cref{fig:results:fit_GaAs30kV}, where the fit in general is good but misses on the background between 0 and 2.5 keV.
The main peak effect on the background is changing both the value and the shape of the background.


% background shape
The shape of the background is varying between the spectra, and is affected by the peaks and the acceleration voltage.
All the 5 kV spectra decrease more or less linearly from 1 to 5 keV.
This is due to the overvoltage, which lowers the possible background radiation to zero after 5 keV in the 5 kV spectra.
When the acceleration voltage is just 5 kV, the critical ionization energy is not higher than 5 keV.
In the GaAs, Si and Mo the relative height of the background decrease with higher acceleration voltage.
The background in the Cu spectra increase with higher acceleration voltage.
The most similar background signal over different voltages are in the NW spectra. % discuss: thin sample -> less background?
This similarity is due to the fact that thin samples produce less background radiation than bulk samples.
In general, backgrounds in the acquired spectra are low, but with different shapes.



\subsection{The strays and artifacts}
\label{sec:discussion:general:strays}

In addition to the characteristic peaks and the background, there are also artifacts and strays in the spectra. % discussion: lower peaks are super important, eg in the Al spectra where it is small amounts of Mg and Mn, probably. 
The background is an artifact which already have been discussed.
One of the artifacts that will be discussed below is X-rays generated outside the area of the beam.
Understanding the details in a spectrum is key for the qualitative analysis, which is the foundation for the quantitative analysis.
Identifying peaks as strays or artifacts can be used to exclude certain elements, as well as making the analyst more certain of what elements are present.
Lower peaks are central for the analysis.
One example of this is the Al spectra, where two lower peaks match with the energies of Mg and Mn.
Asserting what is a stray or artifact and what is a characteristic peak can be challenging, as they can be very similar to the characteristic peaks.
An example of this is in the NW spectrum, where the two Mo L-peaks are exactly where the potential coincidence peaks of the L-lines of Ga and As would be.
This makes the qualitative analysis harder, because the peak can be mistaken, and the quantitative analysis more uncertain, because the signal in the Mo L-peaks get higher if the coincidence artifact peaks are present.
Generally, labeling peaks as strays or artifacts takes time, but it is a crucial part of the analysis.

% Si Ka as internal fluorescence peak, and O Ka and C Ka
All the spectra share some common strays and artifacts.
All the strays and artifacts explained are described in detail in Goldstein \cite{goldstein_scanning_2018}.
The bremsstrahlung background radiation is present in all spectra, but with different shapes and intensities.
The internal fluorescence peak present in all but the Si spectra, which is the Si K$\alpha$ peak at 1.74 keV coming from the excitation of Si inside the dead layer of the detector.
In the Si spectra, the Si K$\alpha$ peak is from the Si wafer.
The intensity of the Si K$\alpha$ peak could also be increased by excitations of Si by X-rays from outside the beam, because of the Si wafer.
Both O K$\alpha$ and C K$\alpha$ are also present in all spectra, which could be an oxide layer and contamination on the sample.
Carbon coating on the sample by the beam was visible on the Cu-tape images, showing that there is carbon some contamination on the sample.


% Sum peaks
Another artifact present in almost all spectra is sum peaks, or coincidence peaks.
No sum peak is visible in the NW spectrum, except for the possibility of the sum peaks of the L-lines of Ga and As overlapping with the Mo L-peaks.
There are no sum peaks in the Cu spectra, but these spectra are as explained earlier questionable.
Sum peaks are a peak where two X-rays are counted as one, giving a peak at the sum of the energies of the two X-rays.
This occurs because the detector can only count one X-ray at a time, and since the counting does take some time, two X-rays can be registered as one.
The process is dependent on the counting, which takes a certain amount of time, and this time is the dead time.
In other words, a higher dead time will result in more signal in the sum peaks.
A good example of this is the GaAs spectra, where the 5 and 30 kV spectra have DT at 33 and 30\% and show almost no L-line sum peaks, while the 10 and 15 kV spectra have DT at 65 and 58\% and clearly show the L-line sum peaks.
The NW spectra have the lowest dead time, which might be why there are no sum peaks in the NW spectra, which fit well with the difference in the GaAs bulk spectra.
Another explanation is that the NW spectra is the only one with a thin sample, which could result in less sum peaks.
Labeling a sum peak correctly is important, else the signal can be mistaken for a characteristic peak.

% split the long paragraph into two
One example of important labeling is the Si spectra, where the sum peak is close to the Sb L$\alpha$ peak.
Analyzing this peak could be done by looking at the resolution and trying to figure out if the difference of 3.60 - 3.48 keV could be resolved, since the resolution at lower energies gets better.
A faster and more reliable solution to this problem is to use the knowledge of the Sb L-peaks, which always come in a series of multiple peaks because of the splitting of the L-lines in Sb, as explained in \cref{sec:theory:theoreticalxray:naming}.
This splitting effect of the Sb lines are visible in the NW spectra, where the Sb L-peaks are split into three peaks with heights matching the weights in HyperSpy.
An even more reliable, but more time-consuming solution, could be to acquire multiple spectra with different DT.
Dead time at around 30\% was recommended by the supervisor of this project, Antonius T. J. von Helvoort, and is well below the problematic dead time of >60\%.
The dead time on the nanowire area was closer to 20\%, which is what Goldstein \cite[page 223]{goldstein_scanning_2018} recommends.
An issue with the sum peaks when doing quantitative analysis, is that the signal in the sum peaks are supposed to be a part of the signal in the characteristic peaks.
When looking at the Al spectrum, with DT at 22\%, the sum peak is in the same size range as the other lower peak, which would clutter the quantification of the potential alloy.


% Al alloy
The Al spectrum of the FIB stub are labeled with three peaks in the same size order as the Al K$\alpha$ sum peak.
These three peaks are from Mg, Si and Mn, which could be present in the FIB stub.
An Al alloy with Mg and Si is quite common, according to the supervisor of this project.
An Al alloy of Al, Mg, Mn, Si, Fe and Cu is analyzed in an article by Wojciech \cite{al_alloy}, and an alloy like that would explain all the peaks and the very low but barely visible signal from Fe K$\alpha$.
Another possible explanation for the Mn peak is that the FIB stub used had some contamination, which could be tested by taking spectra of other FIB stubs.
Determining how much of the Si peak is from the alloy and how much is the internal fluorescence peak could be done by taking spectra at different DT.


% Ni in NW, and short on escape peaks
Another peculiar peak is the Ni K$\alpha$ peak in the NW spectra.
The projects' supervisor claim that it is unlikely to be a Ni peak, as this have not been observed in the NW sample earlier.
Making the nanowire sample was not a part of this thesis, only analyzing it with SEM EDS.
The energy of the peculiar peak match well with the Ni K$\alpha$ energy at 7.50 keV, but the peak might be an escape peak from Gs K$\alpha$ at 9.24 keV.
An escape peak is an X-ray that excites Si in the detector, and thus loose 1.74 keV energy before being detected.
However, an issue with this explanation is the peak at 0.85 keV, which would be the Ni L$\alpha$ peak.
The peak is not very well-defined, as it overlaps much with the Cu L$\alpha$  and partly Ga L$\alpha$ peaks.
Other escape peaks in the rest of the spectra are hard to identify, as the E-1.74 keV of the main peaks usually falls below zero.
One exception is the Mo L$\alpha$ peak, where a potential escape peak align with O K$\alpha$.
In conclusion, it is not possible to determine certainly if the peak is an escape peak or a real Ni peak, but it could be a real Ni peak.



% artifact: radiation in NW outside beam, Mo, Cu and Sb
Other artifacts seen in the spectra are radiation signals from outside the beam.
These signals come both from electrons which scatter in the beam and hit other parts of the sample or the chamber, and from X-rays which are generated and have enough energy to excite and generate new X-rays.
The last one is what happens in the detector with the Si K$\alpha$ internal fluorescence peak.
The secondary X-rays, i.e. X-rays generated from X-rays, are also emitted from the whole interaction volume.
The interaction volume of X-rays is large, since the X-rays are emitted in all directions and do penetrate deep into the sample, as stated in \cref{sec:theory:theoreticalxray:formation}.
Examples of this type of artifact is the Mo and Cu signal in the NW spectra.
The grid is made of Cu, but the nanowire sampled is far from the grid.
The Mo signal is from the Mo disk, which also is far from the sampled area.
Signals from outside the sampled area can both be confusing and clutter the quantification, for example in the NW spectra where the sampled area is just the nanowire but the spectrum show signals from a larger area.


One last artifact to be discussed is the unknown peaks, which for instance is present in the NW spectrum at 0.38 keV.
This energy is close to N K$\alpha$ at 0.392 keV.
The Si spectra have an unknown at 0.08 keV, and this peak is very high in the 5 keV spectrum.
If it is from a characteristic line, it could be Li K$\alpha$ at 0.054 keV or Be K$\alpha$ at 0.108 keV.
Another unknown peak is present in the Mo spectra at 0.18 keV.
The Mo unknown match best with B K$\alpha$ at 0.183 keV.
Making conclusions about the unknown peaks would be unreliable conclusions, as all the unknown peaks are low in energy, and it is shown in \cref{tab:results:calibration-peak-accuracy} that the low energy peak accuracy is not very good.
In addition, the EDS system is not well-designed for the low energy peaks.
This is partly because of the high absorption of the low energy X-rays, making detection difficult.
The conclusion for the unknown peaks is that they stay unknown, and could be investigated further by experimenting with e.g. low acceleration voltages.


There are other details in the acquired spectra that could be discussed, but time is limited and even though details are interesting they are not always relevant to the main goal of a project.
The details included were discussed because they were considered relevant and to show that the data was analyzed in detail.









\section{Quantification in AZtec}
\label{sec:discussion:az_quantification}
%How accurate is the out-of-the-box quantification in AZtec?

\hyperref[subproblem1]{Sub-problem~\ref*{subproblem1}} was to do quantification in AZtec.
The analysis in AZtec was done on the GaAs bulk data, and are given in \cref{tab:initial_quantification}.
The data was treated as both a SEM and a TEM signal, because of the limitations in HyperSpy, which are discussed in \cref{sec:discussion:steps}.
AZtec has a GUI for analysis, but it is not possible to see what is done with the data at the different steps.

For all four spectra the quantification was most accurate when treating the data as a SEM signal.
This was not unexpected, since the spectra in fact are SEM spectra.
It is interesting that the most accurate SEM quantification at 15 kV, while the most inaccurate TEM quantification at 15 kV.
In general, the quantification as SEM signals are very accurate, all withing 5\% of the correct value for Ga and As.
The AZtec and HyperSpy quantification on the 5 and 30 kV spectra are very similar, which could imply that they use the same method, i.e. the CL method.
However, the quantification on the 10 and 15 kV spectra are very different, because the HyperSpy quantification breaks down.
This break down in covered more in \cref{sec:discussion:failure}.

In general the quantification done on the correct type of signal is quite accurate in AZtec, but the problem is that the quantification is done as a black box.
Adjusting the parameters of for example the background fitting or the peak finder is not possible, and the user cannot see what is done with the data at the different steps.
An issue with this is visible in the initial AZtec plot in \cref{fig:GaAs30kV_AZ}, where the Ga K$\beta$ peak is not identified.
The peak is clearly visible in the unscaled spectrum, but the peak finder in AZtec does not find it.
Clicking on the peak opens a window where the user can select what peak this would correspond to, but the only options are a selection of elements where the peak is obviously wrong.
Not being able to identify the peak that big should raise concern, especially since the peak is overlapping with the As K$\alpha$ peak and thus would affect the quantification.
Since the quantification process is hidden, the user does not know if AZtec deals with the overlapping peaks correctly.









%
%
\section{Analysis steps in HyperSpy}
\label{sec:discussion:steps}
% What are done with the data at the different steps in the analysis when using HyperSpy?

\hyperref[subproblem2]{Sub-problem~\ref*{subproblem2}} was to figure out what the steps are doing in the qualitative analysis in HyperSpy.
HyperSpy have documentation online, and the following subsections explain how the analysis was done in HyperSpy.


Each subsection starts with some code lines, followed by an explanation of what the lines do.
All variables inside crocodile need to be set by the user, e.g. \verb|<element_list>| would be set to \verb|['Ga', 'As']| for the GaAs wafer.
An example notebook with quantification of the GaAs wafer is attached in APPENDIX.
\brynjar{Make a notebook with GaAs quantification in HyperSpy, with the data somehow.}







\subsection{Loading the data and specifying the elements}
\label{sec:discussion:steps:load}

\begin{quote}
    \verb|s = hs.load(<filepath>, signal="EDS_TEM")|

    \verb|s.set_elements(<element_list>)|
\end{quote}

The first step in the analysis is to load the data as a HyperSpy \verb|signal| type, and specifying the signal as TEM.
The \verb|signal| type is a class in HyperSpy that contains the data and the metadata, and it has methods for analysis.
The \verb|signal| type must be specified as TEM, because the \verb|signal| type for SEM is very limited and does not have a method for quantification.
When using .emsa files from AZtec, as is done in this project, the metadata contains some relevant and some irrelevant information.
The information relevant later in this project is:
acceleration voltage, dispersion, zero offset, energy resolution Mn K$\alpha$,
After loading, it is possible to plot the data with \verb|s.plot()|.

Already at this point there is a big problem with using HyperSpy on the acquired data: the analysis methods are not implemented for SEM but for TEM.
As explained by Skomedal in her master's thesis \cite{skomedal_improving_2022}, the quantification with the Cliff-Lorimer method of TEM EDS data use approximations which are valid for thin samples.
The approximation is that the sample is thin enough to ignore absorption and fluorescence, which is a bad approximation to use on bulk SEM EDS data.
Still, the results show that it is possible to quantify the elements in the GaAs wafer with the Cliff-Lorimer method and get plausible results, but also that the analysis breaks down occasionally. % Copilot: but the results should be taken with a grain of salt.
Implementing quantification from the SEM type signal in HyperSpy have been discussed on the repositories GitHub issues page\footnote{\url{https://github.com/hyperspy/hyperspy/issues/2332}}.
The topic have been discussed in 2020, 2017 and 2015.
People have been working on quantification of SEM EDS data, but the work have not been finished yet.


% Using EDS_TEM since EDS_SEM does not have all these functions.
% Commercial packages do quantify SEM signal, and they are kinda good at it.
% Should be more accurate on NW sample, but is it?
% Reference the discussion on GitHub?


The quantification done with the CL method in HyperSpy on the three different calibrations in \cref{tab:results:calibration-quantification} are all within 10\% of the expected composition.
Carter and Williams \cite[p. 612 and 648]{carter2016transmission} state that the accuracy of EDS is at best $\pm$ 3-5\%, but that it could be reduced to around $\pm$ 1.7\% with very long acquisition times and a careful analysis.
Carter and Williams claim that quantitative errors less than $\pm$ 5-10\% takes a lot of time and effort, and compositions with error below 5\% should be regarded extra carefully and with suspicion.
The best result, i.e. the result closest to 50\%, from the HyperSpy CL quantification is strangely from the AZtec calibration with a 6.25\% error.
It is strange that the AZtec calibration is the best, because that is the calibration which misses most on the line accuracy in \cref{tab:results:calibration-peak-accuracy}.
This implies that the calibration is not the most important factor for the quantification, at least not when the calibration is around $\pm$ 1\%.
The different calibrations are discussed further in \cref{sec:discussion:calibration}.
In the 30 kV GaAs sample the signal-to-noise ratio is good, the sample time was long and the peaks are well resolved, which make the input data good and allows for better quantification.
The CL method is known to work on SEM data, but normally one would also do the ZAF correction, which is described in chapter 19.10.3 of Goldstein \cite{goldstein_scanning_2018}.
The ZAF correction adjust the signal for the atomic number effect, the absorption in the bulk of the sample and the X-ray fluorescence of new lines with lower energy than the initial characteristic X-ray.
Since Ga and As are number 31 and 33 in the periodic table, it could be that the ZAF corrections are small and would not have a big effect on the results.
When doing the quantification it was tested to include O and C, but that changed the results from plausible to completely wrong.
The quantification analysis also broke down when using the 10 and 15 kV spectra, but the reason for that was not clear.
The breaking down of the analysis is discussed further in \cref{sec:discussion:failure}.


Results in this project show that the CL method in HyperSpy for TEM EDS data sometimes yield plausible results on SEM EDS data and sometimes break down, thus the method should be used with caution.
The goal of this project was not to do or to implement cutting edge quantification of EDS data from a SEM sample, but rather to understand the analysis steps and what factors that could affect the results.
Thus, using the quantification method from the TEM signal type was regarded as good enough for the principles tested in this project.









\subsection{Removing the background linearly}
\label{sec:discussion:steps:background}
\begin{quote}
    \verb|bw = s1.estimate_background_windows(windows_width=<number>)|

    \verb|iw =  s1.estimate_integration_windows(windows_width=<number>)|
\end{quote}

The next step is to remove the background, which with the above code is done by a linear fit.
The background can be removed through model fitting, which is covered in \cref{sec:discussion:steps:model_fitting}.
The variable \verb|windows_width| sets how wide the windows are for the background and integration, measured in FWHMs.
A good starting value for \verb|windows_width| is 2, but it should be tested by the user with a plot to see if the background will be removed correctly.
The estimated windows can be plotted with:

\begin{quote}
    \verb|s.plot(xray_lines=True, background_windows=bw, integration_windows=iw)|
\end{quote}


Plotting has proven to be a very useful tool for understanding what the different steps in the analysis do.
Unfortunately, the implemented plotting in HyperSpy is limited.
For example, when plotting a modelled spectrum with Ga and As, the model contains all the peaks in the HyperSpy library and all the peaks are plotted, but it is not possible to see what the different peaks are.
In other words, the plot of a model can show all the independent components, but adding a legend is not an option.
Another limitation of the plotting is the interactivity when saving the plot.
Matplotlib requires the code to run in the background for it to be interactive, while Plotly can save the plot as an interactive HTML file for later inspection.
One of the advantages with the plotting in HyperSpy is how accessible it is to plot in the different steps, which the user can use to understand and verify the analysis.
The HyperSpy plotting was probably not made with the intention of being used for publication, but rather for quick and easy plotting of the data.
If that is the case, the plotting serves its purpose well and has proven to be very useful for this project.
% Copilot did this: One of the authors of HyperSpy, Tomas Ostasevicius, has been working on a new plotting library for HyperSpy, which will be released in the next major release of HyperSpy.

One of the more helpful insights from plotting in this project was that removing the background is not trivial.
This is especially true for background signals modelled as a polynomial.
Linear background removal works well for some peaks, for example the K-lines of Ga and As, but not for the L-lines.
The background around the K-lines are more linear, because of the exponential decay of the background.
Around the L-lines the background is affected by the absorption of the Bremsstrahlung lower than ~2 keV and the observation of higher background levels below the highest peak in the spectrum.
The background removal is discussed further in \cref{sec:discussion:modelling}.








\subsection{Quantification after linear background removal}
\label{sec:discussion:steps:quantification:linear}

\begin{quote}
    \verb|s_i = s.get_lines_intensity(background_windows=bw, integration_windows=iw)|

    \verb|k_factors = [<k-factor 1>, <k-factor 2>]  |

    \verb|quant = s.quantification(s_i, method='CL', factors=k_factors)|

    \verb|print(f'E1: {quant[0].data[0]:.2f} \%, E1: {quant[1].data[0]:.2f} \%')|
\end{quote}

The quantification is done with the four lines of code above, where the last one prints the results.
The first line gets the intensity of the peak corresponding to the lines of the specified element.
HyperSpy selects automatically which lines to use for quantification.
To see which lines are used, the \verb|s_i| variable can be printed.
The second line sets the k-factors.
The k-factors in this project have been the one from AZtec, which are theoretically estimated.
The third line does the quantification, where the method is specified.
The method is the Cliff-Lorimer method, described in detail in Mari Skomedal's master thesis \cite[Sec. 2.2.3]{skomedal_improving_2022}.
HyperSpy has a method for quantification with the zeta factor method.
The zeta method requires the value for the beam current, which was not measured in this project. \footnote{Results from the zeta method can be converted to the cross section method, see the page "EDS Quantification" in the HyperSpy documentation.}
% \footnote{Results from the zeta methon can be converted to the cross section method, see \url{http://hyperspy.org/hyperspy-doc/current/user_guide/eds.html#eds-quantification}.}


% k-factors
The k-factors are essential for the Cliff-Lorimer quantification, and the k-factors listed in \cref{tab:results:k-factors} give some insight into how AZtec calculates the k-factors.
From the results it is clear that AZtec at least adjust the k-factor for element and for voltage.
It could be that factors like the beam current and time live could affect the k-factor, but this was not investigated in this project.
The L-line k-factors are start at 1.1 for 5 kV and increase to 1.2 for 15 kV.
The As k-factor for the L-line at 5, 10 ad 15 kV is 11\%, 7\% and 6\% greater than for Ga.
The K-line k-factor are 3.3 for Ga and 4.2 for As, implying either a high sensitivity for higher voltages or two different models for calculating the k-factors.
Another possibility is that the K-lines and L-lines have a separate model for calculating the k-factors.
This can be tested by extracting the k-factors for the K-lines from the 15 kV spectrum, as the 15 kV spectrum do have peaks for both the K-lines and L-lines.
The k-factors for Ga are in all four cases higher than for As, which makes sense, as all the Ga lines are higher and have more counts than the As lines.
Quantification of the ratio between the Ga and As peaks are shown in \cref{tab:results:ratios}, where it is clear that the k-factor push the ratio towards 1.
The peak ratio times the k-factor for 5 kV is 1.1, and the next closest to 1 is 1.3 for 30 kV.
This result implies that the theoretically calculated k-factors could be better for high and low voltages.








% overlapping peaks in sum, why to use modeled peaks and not raw counts.
\subsection{Removing the background with model fitting}
\label{sec:discussion:steps:model_fitting}
Another way to remove the background is to fit a model to the data.
This step would be done right after loading the data.
If the raw data contains a zero peak, as is the case for most Oxford instrument EDS detectors, the zero peak needs to be removed before fitting the model.
This requirement can easily cause problems and confusions, as this step is not very clear in the HyperSpy documentation.
The reason for this being not that clear, is probably that different detectors have different zero peaks, and the zero peak is not always at the same place.
The zero peak is removed by skipping the first n channels, where n=30 works well with the data from the GaAs wafer.
The model fitting is done with the following code:

\begin{quote}
    \verb|s = s.isig[<zero_peak_last_index>:]|

    \verb|m = s.create_model(auto_background=False)|

    \verb|m.add_polynomial_background(order=12)|

    \verb|m.add_family_lines(<list_of_element_lines>)|

    \verb|m.plot()|

\end{quote}

The lines above removes the zero peak, create a model from the \verb|signal| s, adds a 12th order polynomial, add the lines of the elements in the \verb|signal|, and plot the model.
This model is not fitted, it is just a generated spectrum with the lines of the elements.
Eventually, the method \verb|create_model()| can take the boolean argument \verb|auto_add_lines=True|, which will automatically detect the elements in the sample.
The model consists of a number of components, which can be accessed with \verb|m.components|.
The components are all the Gaussian peaks in the spectrum, in addition to the background as a 12th order polynomial.
The Gaussian components are based on the lines that the added elements in \verb|<element_list>| have.
If \verb|auto_background| is not set to false, HyperSpy will add a 6th order polynomial.
The order of the polynomial can be changed, but it should be tested by the user to see if it is a good fit.
6th order polynomials work, but as shown in \cref{fig:results:fit_GaAs30kV}, the 12th order polynomial has a lower RMS error and is thus preferred.
Further, the model must be fitted.

\begin{quote}
    \verb|m.fit()|

    % \verb|m.fit_background()| % not neccessary

    \verb|m.plot()|
\end{quote}

The first line fits the model to the data to the components and the second line plots the model.
HyperSpy have an own option for fitting only the background.
Since the background is one of the components in m, it is fitted with the code line above.






\subsection{Quantification after model fitting}
\label{sec:discussion:steps:quantification:model}

\begin{quote}
    \verb|m_i = m.get_lines_intensity()|

    \verb|k_factors = [<k-factor 1>, <k-factor 2>] |

    \verb|quant = s.quantification(s_i, method='CL', factors=k_factors)|

    \verb|print(f'E1: {quant[0].data[0]:.2f} \%, E1: {quant[1].data[0]:.2f} \%')|

\end{quote}

The quantification after model fitting is done in the same way as in \cref{sec:discussion:steps:quantification:linear}, but with intensity from the model instead of the signal.
When modelling GaAs, the model can add the intensity from both K-lines and L-lines.
Since AZtec only gives the k-factors for either the K-lines or the L-lines, the user must remove the lines without k-factors before quantification.
As explained in \cref{sec:discussion:general:intensities}, overlapping peaks need to be modelled to get the correct intensities.






\subsection{Calibrating the spectrum with the HyperSpy model}
\label{sec:discussion:steps:HyperSpycalibration}

\begin{quote}

    \verb|m.calibrate_energy_axis(calibrate='scale')|

    \verb|m.calibrate_energy_axis(calibrate='offset')|

\end{quote}

The two lines above calibrates the spectrum with the HyperSpy model and updates the dispersion and zero offset.
The metadata in the \verb|signal| s is updated with the new calibration.
Thus, doing the previous step with quantification after model fitting can give a more correct quantification.
This is the HyperSpy calibration that is used in \cref{tab:results:calibration-quantification}.
As shown in the table, the HyperSpy calibration gives a better peak accuracy than the calibration from AZtec, and it is about as accurate as the self produced calibration done on the GaAs 30 kV spectrum.
This self produced calibration is discussed in \cref{sec:discussion:calibration}, after a discussion of the peak and background modelling in the next section.












\section{Peak and background modelling}
\label{sec:discussion:modelling}
% How can the peaks and the background be modelled?


\hyperref[subproblem3]{Sub-problem~\ref*{subproblem3}} was to find out how the peaks and the background can be modelled.
The model was built without HyperSpy, with the idea of making the steps clear for a user.
Once the model is fitted to the data, it can be used to calibrate and quantify the peaks and background, which is discussed in \cref{sec:discussion:calibration}.
This can be done by comparing the peak ratios, i.e. the relative areas under the peaks, and using these ratios to calculate the Cliff-Lorimer quantification, as shown in \cref{tab:results:ratios}.
In the table the ratio is also multiplied with their respective k-factors, to get the Cliff-Lorimer quantification.

% identyfy peaks with peak finder
% problem: overlapping peaks, eg. Mo
% problem: includes zero peak. Is that an issue?
The first step in creating a model is to identify the peaks.
The peaks are assumed to be Gaussian curves.
Other possible shapes are Lorentzian curves, but that has not been a part of this project.
The initial way of identifying peaks was that the user manually identified the peaks.
Later the peaks were identified with the function \verb|scipy.signal.find_peaks()|, using the argument \verb|prominence=0.01|.
The prominence is the height of the peak above the background\footnote{\url{https://en.wikipedia.org/wiki/Topographic_prominence}}.
As seen in \cref{fig:results:fit_GaAs30kV}, the given prominence identifies many but not all the peaks.
Further work on the peak finder is needed to find a good and robust way of identifying the peaks.
The figure also shows that the peaks are well-fitted by the model, while the background is fitted fairly well.



% make Gaussian and a polynomial
% problem: initial background guess. Solution: clip out the peaks with linear interpolation and fit a polynomial to the rest.
% problem: normalized data. initial guesses are hard on counts, and fitting is slower.
% early problem, now solved: some Gaussians would be put as the background. solution: fit both Gaussians and polynomial
Once the peaks have been identified in the data, the next step in creating a model is to fit a Gaussian curve to each peak and a polynomial to the background.
In order to do this, the model components need initial guesses for their parameters.
For the background, this means providing initial guesses for the coefficients of the polynomial.
A good way to do this is to remove the peaks from the data using linear interpolation, and then fit a polynomial to the remaining data.
The coefficients of the initial fitted polynomial can then be used as the initial guesses for the background in the model.
Each Gaussian is described by its mean, standard deviation, and height, as shown in \cref{eq:theory:empirical:gaussian}.
The mean is the peak position, which has its initial guess from the peak finder.
The standard deviation is the width of the peak, where $\textnormal{FWHM} = \textnormal{std}*2*\sqrt{2*\ln{2}}$\footnote{FWHM defined at: \url{https://en.wikipedia.org/wiki/Full_width_at_half_maximum}}.
The height is the amplitude of the peak.
The easiest way to get the initial guesses for the standard deviation and the height is to normalize the spectrum and set both parameters to 1.
In the normalization the highest peak was set to 1, and the rest of the peaks were scaled accordingly.
With the initial guesses, the whole model is ready to be fitted.

% why normalize
Normalization is a technique that is often used in data analysis to make the fitting process faster and more stable.
In the case of this project, it was found that normalizing the data was necessary in order to avoid failure of the SciPy fitting algorithm.
This failure is likely due to the fact that \verb|scipy.optimize.curve_fit()| is optimized for certain types or ranges of data, and normalizing the data allows it to handle the data more effectively.
It is important to note that although the data is normalized for the purpose of fitting, the quantification of the peaks is based on the ratios between the peaks, which are not affected by the normalization.
This means that the normalization does not affect the accuracy of the quantification, but only the speed and stability of the fitting process.
However, the perceived spectrum is affected by the normalization, which is important in the qualitative analysis.
In this project, different normalization techniques were explored in order to find the one that provided stable results with SciPy, while still allowing the qualitative analysis to be performed.

% the selected normalization
The normalization that was used in the end was to set the highest peak to 1, and scale the rest of the peaks accordingly.
This normalization, with some scaling and cropping of the figure, allowed the peaks to be visible and comparable, while still allowing the qualitative analysis to be performed.
No special features were observed to be lost by using this normalization.
Some EDS users and textbooks prefer to use the logarithmic scale on the y-axis instead of normalizing the data.
The logarithmic scale is a good way to make the spectrum easier to read, but it does not affect the fitting process.
In addition, plotting with a logarithmic scale was tested while doing the qualitative analysis, but it was found that the logarithmic scale provided less detailed information on the smaller peaks and strays than the linear scale.
In the initial AZtec plot in \cref{fig:GaAs30kV_AZ} the spectrum is plotted both with a linear and a logarithmic scale.
Using the logarithmic scale is in the end a user preference.
Thus, the linear scale with normalization was chosen as the best way to visualize the spectrum for the qualitative analysis, and as the best input for the fitting process.


% curve fit
% problem: sometimes fails
With the model components ready and the data normalized, the model can be fitted to the data.
The \verb|curve_fit()| function uses the Levenberg–Marquardt algorithm to fit the model to the data, and returns the optimal fitted parameters.
Fitting both the Gaussians and the background at the same time makes the fitting more stable.
One of the first iterations, where the user manually inputted the peaks, the fitting tended to partially fail.
The issue was that the fitting only was done on the peaks.
To minimize the error in the fitting, one of the Gaussian curves with a low amplitude was moved and got a huge standard deviation, which compensated the background.
This was fixed by fitting both the Gaussians and the background at the same time.
Doing this made the fitting both better, and it failed less often.

% problem with severely overlapping peaks
The issue of severely overlapping peaks was encountered when fitting the Mo spectrum.
The Mo L$\alpha$ and L$\beta$ peaks are very close to each other, and even though the fitting algorithm would handle this, the peak finder would not recognize the overlapping peaks as two separate peaks.
This problem can be fixed manually, but with the limited time in this project it was categorized as an edge case that would not be handled.




% \ton{Now I am happy with the discussion until this point (13.12.22). How would you rate it? Any suggestions on the bigger picture of the discussion? I do need to wrap it up soon, because I still need to fill in some theory, fix the conclusion and the introductions.}
% Reply:
%%%%%%%%%%% Good you are happy, it is your text. I have scrolled through fast. It is a good length, you alert to general and specific observation. Ok.
%%%%%%%%%%% How code formulation is, works less well in a long text.
%%%%%%%%%%% If you can break up the text with a few figures, visulaizing the discussion that would be fine, if possible.
%%%%%%%%%%% But for now focus on finishing the other parts.
















%
\section{Calibration}
\label{sec:discussion:calibration}
%     How good is the calibration in AZtec and HyperSpy?

\hyperref[subproblem4]{Sub-problem~\ref*{subproblem4}} was to figure out how good the calibration is in AZtec and HyperSpy, which lead to making a new calibration in Python.
The calibration has been discussed some in \cref{sec:discussion:general:intensities,sec:discussion:steps:load,sec:discussion:steps:HyperSpycalibration}, and is here discussed more in depth.

% importance of calibration
Calibration is an important step in the analysis, as it ensures that the results obtained from the analysis are accurate and reliable.
If the dispersion is a few percent off, the error in the analysis could be significant as the error is accumulates with higher energies.
In general, calibration involves the comparison of the measured values with a known reference standard, in order to determine the accuracy and precision of the measurement system.
In this project, the reference was two known peaks.
Calibration process is important because it allows the user to account for biases or errors in the measurement system, and to correct for them in order to obtain more accurate results.
Additionally, calibration can also help to identify any potential problems or issues with the measurement system, allowing the user to take appropriate action to address these issues.
A well calibrated system is important in high accuracy measurements.

% calibration in AZtec
When working with AZtec, the data is read with a built-in calibration.
It might be an option to calibrate the data in AZtec, but this was not investigated in this project.
One thing is sure, and that is that AZtec does not calibrate the spectrum automatically, as all the spectra were extracted with the same calibration.
It might be that the calibration of the SEM APREO EDS detector was set e.g. upon installation, and have not been changed since then.
Since the AZtec calibration had the worst peak accuracy, it would be interesting to see if changing the calibration of the instrument would change the black box quantification in AZtec.
This step was not included in the scope of this project.


% calibration in HS
A step that was included in the scope of this project was to calibrate the data in HyperSpy.
The calibration is described in \cref{sec:discussion:steps:HyperSpycalibration}, which gave a dispersion 2.8\% higher than the calibration in AZtec and one more channel in the zero offset.
The higher dispersion is shifting the whole spectrum to the right, because the energy per channel is higher.
The higher zero offset is shifting the spectrum to the left, as more channel values are negative, which does not have a real life interpretation.
This left and right shift is making the whole spectrum fit the peaks better, as quantified in \cref{tab:results:calibration-peak-accuracy}.
The HS calibration was done on GaAs, and gave very similar results as the self-made calibration.


% why doing the self calibration. understand and verify the calibration in HS
The self-made calibration was made with two goals in mind: to understand the calibration process better and to verify the calibration in HyperSpy.
HyperSpy is open-source software, but reading the source code is not the most efficient way to understand how the calibration is done.
The calibration in HyperSpy is done with a model of the spectrum, which is fitted to the data.
Thus, the self-made calibration was based on the same principle.
A model was made and fitted, and two far apart peaks were used for calibration.
Which peaks to use is discussed below.
The self-made calibration was done on two spectra, GaAs and Mo.
The Mo spectrum gave a dispersion 4.0\% higher than the calibration in AZtec, and it was probably too high, based on the poorer peak accuracy.
The Ga spectrum gave a dispersion 3.0\% higher than the calibration in AZtec, and the peak accuracy was similar to the calibration in HyperSpy.
Quantified with the RMSD, the self-made calibration is better than the HS calibration, but too few spectra have been tested to make a final decision of which calibration is better.
The HS and self-made calibration preform quite bad at C K$\alpha$, but this peak is not as useful.
Carbon is often an impurity in EDS samples, both present in the chamber and potentially on the sample.

% Selecting peaks for calibration
The peaks used for calibration should be far apart and have a good signal-to-noise ratio.
The channels between the peaks are interpolated, while the channels outside the peaks are extrapolated.
Extrapolated channels can potentially get a larger error, as error in the dispersion accumulates.
The peaks need a good signal-to-noise ratio, because the fit needs to be good to find the correct peak position.
The problem with the Mo spectrum, where the peaks are further apart, was probably that the Mo K$\alpha$ peak was not good enough to fit, because the signal was low.
The value of the Mo K$\alpha$ peak is around 2\% of the Mo L$\alpha$ peak, while the lower calibration peak in the GaAs spectrum is 20\% of the higher peak.
The problem with the Mo spectrum could have been a poor fit of the Mo L$\alpha$ peak, which is overlapping with the Mo K$\alpha$ peak, because the peak finder struggles with this severely overlapping peak.
However, the overlapping problem was solved manually for the calibration on the Mo spectrum.
If the problem was lower signal-to-noise ratio of Mo K$\alpha$, the problem could have been solved by using a longer counting time.
This could be investigated in the future, to try to optimize the calibration of the detector.


% Selecting the correct theoretical value, and the difference between XRB and HS
% fig:results:Ga-K
% Something about how the calibrated peak of Ga K$\alpha$ is directly on XRB K$\alpha_1$.
One last, but important, aspect is the theoretical value of the peaks.
To get the calibration right, the reference peaks need to be at the correct energy.
In this work, it was discovered that the theoretical values in the X-ray Data Booklet are slightly deviating from the HyperSpy values.
The first thing to note is that the lines listed in the XRB and in HS deviate somewhat, as seen in \cref{tab:theory:Ga-lines,tab:theory:Mo-lines}.
Not all the lines in the table are visible in the spectra in \cref{fig:results:Spectra_Mo,fig:results:Spectra_GaAs}.
The XRB differentiates between K$\alpha$1 and K$\alpha$2, and states that the weight of Ga K$\alpha$2 is 0.51 relative to Ga K$\alpha$1.
If this was true, the Ga K$\alpha$ peak would be an overlapping peak with a broadening on the right side, but as seen in \cref{fig:results:Ga-K}, this is not the case.
The figure show that the peak fit exactly one Gaussian curve, with its center directly on the K$\alpha$ line from HS, which is the K$\alpha$1 line in the XRB.
The XRB claim that the listed lines are the strongest lines \cite[P. 33, Sec. 1.2]{thompson_x-ray_2004}, but it is missing the Mo L$\gamma$3 line, which is visible in the Mo spectrum.
In general, the weights of the lines listed in the XRB and HS seem to be slightly off from the data collected in this project, because some lines are not visible and some are, but this cannot be explained solely by the weights.
It could be that the listed weights would be correct when collecting the data differently or with different materials.


% The author have not been able to find the source of the lines in the HyperSpy liberary, but it might be the NIST database, as this is one of the references in HyperSpy\footnote{link??}.%\url{http://hyperspy.org/hyperspy-doc/current/user_guide/bibliography.html#chantler2005}}.
% Both the XRB and HS include the strongest lines in the spectra, i.e. the K$\alpha$ and L$\alpha$ lines.
% Both lists lines which are not visible in the acquired spectra, but the extra lines in the XRB are not present at all, while some of the extra lines in the HS are visible.
% For example in the Mo spectra a Ll and a L$\gamma$3 line are visible and are listed with matching energies in the HS liberary, but not in the XRB.
% Based on the acquired spectra, a possible explaination for the difference is that the HS lines are based more on empirical data and the XRB lines are based on theoretical calculations.
% This is purely speculation, and should have been investigated further as it have been a source of confusion, but it was not prioritized.



% conclude
% Selecting a calibration material which is both stable, give good signal and is easily available.
% Should be a sample that is easily available. Cu tape would be nice, since it is in all labs and samples.





%
%




%
%
\section{Analysis failure}
\label{sec:discussion:failure}
% When does the analysis fail, both in AZtec and HyperSpy?
\hyperref[subproblem5]{Sub-problem~\ref*{subproblem5}} was to find out when the analysis fails, both in AZtec and HyperSpy.
The time spent on this sub-problem was limited compared to what would have been preferred to get a clearer understanding of both when and why the analysis fails.
The observations done are mostly on when the analysis fails, and not why.
Why the analysis fail would be a good starting point to improve the EDS analysis.

% treating SEM data as TEM data
The fact that the quantification fails when the SEM EDS data is treated as TEM data was expected.
As stated earlier, when doing TEM analysis there are some key assumptions which are not valid for SEM data.
When analyzing SEM EDS data it is necessary to do the ZAF correction, which was described briefly in \cref{sec:discussion:steps:load}.
Implementing the ZAF matrix correction in HyperSpy for the SEM signal would be a helpful contribution to the HyperSpy project, as this has been mentioned as one key missing feature to do SEM EDS quantification with HyperSpy in the GitHub discussion threads.




% HS breakdown at 10 and 15 kV
One of the strangest results in this project was that the quantification failed at 10 and 15 kV in HyperSpy.
The exact same CL quantification code was used on the 5, 10, 15 and 30 kV spectra, but only the 5 and 30 kV spectra gave a reasonable result.
The most puzzling thing is that the code gives results on the 5 and 30 kV spectra which looks similar to the TEM quantification results in AZtec, so the code described above in \cref{sec:discussion:steps} is not completely wrong.
The four spectra look quite similar.
One difference is that the 10 and 15 kV spectra have a dead time which was around twice as long as the 5 and 30 kV spectra.
The different DT is not a sufficient explanation, it is just an observed difference.
The author did not have time to dig deep enough into the source code of HyperSpy to find the reason for the failure.
Possible explanations are the selection of lines to use in the quantification, an error in the code or the extracted data, a bug in HyperSpy for certain settings, something with the data treatment as TEM data, or something else.
The suggestions are not really helpful, but could be a starting point for further investigation.








% Moved to conclusion?

% \section{Main problem discussion}
% \label{sec:discussion:mainproblem}

% % How do different spectroscopy data processing influence the qualitative analysis, and how do they affect the quantitative Cliff-Lorimer analysis in HyperSpy?

% This last section is a direct discussion of the \hyperref[mainproblem]{Main problem statement}, connecting the findings to how EDS analysis could be improved.
% The main problem is how data processing in EDS analysis affects both the qualitative and quantitative analysis.
% The qualitative effects are discussed first, then the quantitative.

% % TODO: wirte here








