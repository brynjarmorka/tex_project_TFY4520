\chapter{Results}

\section{Introduction}
\label{sec:results:intro}
The results are presented in this chapter.
The sections follow the structure of the sub-problems in \cref{chap:introduction}.

%
%
\section{Initial quantification}
\label{sec:results:initial_quantification}
% How accurate it the out-of-the-box quantification in AZtec and HyperSpy?

The initial quantification was done on the data from the GaAs wafer in AZtec and in HyperSpy as out-of-the-box as possible.
The results are presented in \cref{tab:initial_quantification}.
The wafer is a 1:1 alloy of gallium and arsenic, so the atomic percent of Ga and As should be 50\% and 50\% respectively.

\input{tables/initial-quantification.tex}

%
%
\section{Analysis steps in HyperSpy}
\label{sec:results:steps}
% What are done with the data at the different steps in the analysis when using HyperSpy?
\ton{Is this interesting to write about?}

\ton{This section is both presenting what and why we do the steps. That is leaning into the discussion. Should I separate it?}

The next sub-problem was to find out what is done with the data at the different steps in the analysis when using HyperSpy.
In these steps it is assumed that the user have done qualitative analysis and want to do quantitative analysis on a set of elements.
The analysis in AZtec is done as a black box, so it is not possible to see what is done with the data at the different steps.
All variables inside croccodile need to be set by the user, e.g. \verb|<element_list>| would be set to \verb|['Ga', 'As']| for the GaAs wafer.
An example notebook with quantification of the GaAs wafer is attached in APPENDIX.
\brynjar{Make a notebook with GaAs quantification in HyperSpy, with the data somehow.}

\subsection{Loading the data and specifying the elements}
\label{sec:results:steps:load}
\begin{quote}
    \verb|s = hs.load(<filepath>, signal="EDS_TEM")|

    \verb|s.set_elements(<element_list>)|
\end{quote}

The first step in the analysis is to load the data as a HyperSpy \verb|signal| type, and specifying the signal as TEM.
The \verb|signal| type is a class in HyperSpy that contains the data and the metadata, and it has methods for analysis.
The \verb|signal| type must be specified as TEM, because the \verb|signal| type for SEM is very limited and does not have a method for quantification.
When using .emsa files from AZtec, as is done in this project, the metadata contains some relevant and some irrelevant information.
The information relevant later in this project is:
acceleration voltage, dispersion, zero offset, energy resolution Mn $K\alpha$,
After loading, it is possible to plot the data with \verb|s.plot()|.

\subsection{Removing the background linearly}
\label{sec:results:steps:background}
\begin{quote}
    \verb|bw = s1.estimate_background_windows(windows_width=<number>)|

    \verb|iw =  s1.estimate_integration_windows(windows_width=<number>)|
\end{quote}

The next step is to remove the background, which with the above code is done by a linear fit.
The background can be removed through model fitting, which is covered in \cref{sec:results:steps:model_fitting}.
The variable \verb|windows_width| sets how wide the windows are for the background and integration, measured in FWHMs.
A good starting value for \verb|windows_width| is 2, but it should be tested by the user with a plot to see if the background will be removed correctly.
The estimated windows can be plottet with:

\begin{quote}
    \verb|s.plot(xray_lines=True, background_windows=bw, integration_windows=iw)|
\end{quote}


\subsection{Quantification after linear background removal}
\label{sec:results:steps:quantification:linear}

\begin{quote}
    \verb|s_i = s.get_lines_intensity(background_windows=bw, integration_windows=iw)|

    \verb|k_factors = [<k-factor 1>, <k-factor 2>]  |

    \verb|quant = s.quantification(s_i, method='CL', factors=k_factors)|

    \verb|print(f'E1: {quant[0].data[0]:.2f} \%, E1: {quant[1].data[0]:.2f} \%')|
\end{quote}

The quantification is done with the four lines of code above, where the last one prints the results.
The first line gets the intensity of the peak corresponding to the lines of the specified element.
HyperSpy selects automatically which lines to use for quantification.
To see which lines are used, the \verb|s_i| variable can be printed.
The second line sets the k-factors.
The k-factors in this project have been the one from AZtec, which are theoretically estimated.
The third line does the quantification, where the method is specified.
The method is the Cliff-Lorimer method, described in detail in Mari Skomedal's master thesis \cite[Sec. 2.2.3]{skomedal_improving_2022}.
HyperSpy has a method for quantification with the zeta factor method.
The zeta method requires the value for the beam current, which was not measured in this project. \footnote{Results from the zeta methon can be converted to the cross section method, see the EDS Quantification documentation in HyperSpy.}
% \footnote{Results from the zeta methon can be converted to the cross section method, see \url{http://hyperspy.org/hyperspy-doc/current/user_guide/eds.html#eds-quantification}.}



\subsection{Removing the background with model fitting}
\label{sec:results:steps:model_fitting}
Another way to remove the background is to fit a model to the data.
This step would be done right after loading the data.
If the raw data contains a zero peak, as is the case for most Oxford instrument EDS detectors, the zero peak needs to be removed before fitting the model.
The zero peak is removed by skipping the first n channels, where n=30 works well with the data from the GaAs wafer.
The model fitting is done with the following code:

\begin{quote}
    \verb|m = s.isig[<zero_peak>:].create_model(auto_background=False)|

    \verb|m.add_polynomial_background(order=12)|

    \verb|m.add_family_lines(<list_of_element_lines>)|

    \verb|m.plot()|

\end{quote}

The three lines above create a model from the \verb|signal| s, adds a 12th order polynomial, add the lines of the elements in the \verb|signal|, and plot the model.
This model is not fitted, it is just a generated spectrum with the lines of the elements.
Eventually, the method \verb|create_model()| can take the boolean argument \verb|auto_add_lines=True|, which will automatically detect the elements in the sample.
The model consists of a number of components, which can be accessed with \verb|m.components|.
The components are all the gaussian peaks in the spectrum, in addition to the background as a 12th order polynomial.
The order of the polynomial can be changed, but it should be tested by the user to see if it is a good fit.
Further, the model must be fitted.

\begin{quote}
    \verb|m.fit()|

    % \verb|m.fit_background()| % not neccessary

    \verb|m.plot()|
\end{quote}

The first line fits the model to the data to the components and the second line plots the model.
HyperSpy have a own option for fitting only the background.
Since the background is one of the components in m, it is fittet with the code line above.


\subsection{Quantification after model fitting}
\label{sec:results:steps:quantification:model}

\begin{quote}
    \verb|m_i = m.get_lines_intensity()|

    \verb|k_factors = [<k-factor 1>, <k-factor 2>] |

    \verb|quant = s.quantification(s_i, method='CL', factors=k_factors)|

    \verb|print(f'E1: {quant[0].data[0]:.2f} \%, E1: {quant[1].data[0]:.2f} \%')|

\end{quote}

The quantification after model fitting is done in the same way as in \cref{sec:results:steps:quantification:linear}, but with intensity from the model instead of the signal.
When modelling GaAs, the model adds both K-lines and L-lines.
Since AZtec only gives the k-factors for the K-lines, the L-lines must be removed before quantification.


\subsection{Calibrating the spectrum with the HyperSpy model}
\label{sec:results:steps:HyperSpycalibration}

\begin{quote}

    \verb|m.calibrate_energy_axis(calibrate='scale')|

    \verb|m.calibrate_energy_axis(calibrate='offset')|

\end{quote}

The two lines above calibrates the spectrum with the HyperSpy model and updates the dispersion and zero offset.
%%% THE Calibration gave 1% better result, i think. I need to look at it again.
%
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%
%
\section{Calibration}
\label{sec:results:calibration}
% How is the spectrum calibrated, and is AZtec different than HyperSpy?

The next sub-problem was to calibrate the data with a self produced Python script.

% Something about how the calibrated peak of Ga $K\alpha$ is directly on $K\alpha_1$.

%
%
\section{Peak and background modelling}
\label{sec:results:modelling}
% How can the peaks and the background be modelled in a way that is easy to understand?

The next sub-problem was to find out how the peaks and the background are modelled in a way that is easy to understand.

%
%
\section{Background models}
\label{sec:results:background}
% How does different background models affect the quantitative analysis done in HyperSpy?

The next sub-problem was to find out how different background models affect the quantitative analysis done in HyperSpy.

%
%
\section{Analysis failure}
\label{sec:results:failure}
% When does the analysis fail, both in AZtec and HyperSpy?

The next sub-problem was to find out when the analysis fails, both in AZtec and HyperSpy.
% quantification with 